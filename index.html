<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Training-Free Subject Consistency in Text-to-Image Diffusion models using Shared Attention and Regional Feature Harmonization">
  <meta name="keywords" content="StorySync, Training-Free Consistency, Diffusion Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>StorySync: Training-Free Subject Consistency in Text-to-Image Generation via Region Harmonization</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">StorySync: Training-Free Subject Consistency in Text-to-Image Generation via Region Harmonization</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://gopalji.me">Gopalji Gaur</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://zebracat.ai">Mohammadreza Zolfaghari</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://lmb.informatik.uni-freiburg.de/people/brox/index.en.html">Dr. Thomas Brox</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Freiburg,</span>
            <span class="author-block"><sup>2</sup>Zebracat AI</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2508.03735"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2508.03735"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="./static/images/storyboard/storyboard-1.png" height="100%">
        </div>
        <div class="item">
          <img src="./static/images/storyboard/storyboard-2.png" height="100%">
        </div>
        <div class="item">
          <img src="./static/images/storyboard/storyboard-3.png" height="100%">
        </div>
      </div>
 
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <img id="teaser" src="./static/images/storyboard/storyboard-1.png" height="100%"> -->
      <h2 class="subtitle has-text-centered">
        We introduce <span class="storysync">StorySync</span>: 
        a training-free, plug-and-play, consistent subject generation technique 
        that is able to generate story scenes with
a high level of visual consistency of the story characters.
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Generating a coherent sequence of images that tells a visual story,
            using text-to-image diffusion models, often faces the critical challenge
            of maintaining subject consistency across all story scenes.
            Existing approaches, which typically rely on fine-tuning or
            retraining models, are computationally expensive, time-consuming,
            and often interfere with the model's pre-existing capabilities.
          </p>
          <p>
            In this paper, we follow a training-free approach and propose
            an efficient consistent-subject-generation method. This approach
            works seamlessly with pre-trained diffusion models by introducing
            masked cross-image attention sharing to dynamically align subject
            features across a batch of images, and Regional Feature Harmonization
            to refine visually similar details for improved subject consistency.
          </p>
          <p>
            Experimental results demonstrate that our approach successfully 
            generates visually consistent subjects across a variety of scenarios
            while maintaining the creative abilities of the diffusion model.
          </p>
        </div>
        <img src="./static/images/approach.png" height="100%">
        <p class="has-text-centered is-size-6 mt-2 mb-4">
          <em>Overview of the StorySync approach.</em>
        </p>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Multi-seed consistency. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Multi-seed consistency</h2>
          <p>
            <span class="storysync">StorySync</span> is able to achieve consistency
            across multiple seeds. This allows for generating visually consistent subjects
            in different scenes and visual styles.
          </p>
          <img src="./static/images/multi-seed-consistency.png" alt="Multi-seed consistency example" />
        </div>
      </div>
      <!--/ Multi-seed consistency. -->

      <!-- Multi-subject consistency. -->
      <div class="column">
        <h2 class="title is-3">Multi-subject consistency</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              Our method can also generate multiple consistent subjects in a single image.
              This is achieved by sharing attention across subject patches.
            </p>
            <img src="./static/images/multi-subject-consistency.png" alt="Multi-subject consistency example" />
          </div>

        </div>
      </div>
    </div>
    <!--/ Multi-subject consistency. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2> -->

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="storysync">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>

<h2 class="title is-3 has-text-centered">Consistent Subjects</h2>
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item">
          <img src="./static/images/consistent-subjects/1.png">
        </div>
        <div class="item">
          <img src="./static/images/consistent-subjects/2.png">
        </div>
        <div class="item">
          <img src="./static/images/consistent-subjects/3.png">
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Comparison -->
<h2 class="title is-3 has-text-centered mt-6 mb-4">Comparison</h2>
<section class="section pt-2 hero is-light">
  <p class="has-text-centered mb-4">
    We compare our method with existing training-free methods
    (ConsiStory, and StoryDiffusion) in a qualitative manner.
  </p>
  <div class="container is-max-desktop">
    <img src="./static/images/comparison.png">
  </div>
</section>
<!--/ Comparison. -->

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{gaur2025storysynctrainingfreesubjectconsistency,
      title={StorySync: Training-Free Subject Consistency in Text-to-Image Generation via Region Harmonization}, 
      author={Gopalji Gaur and Mohammadreza Zolfaghari and Thomas Brox},
      year={2025},
      eprint={2508.03735},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2508.03735}, 
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            Website source code based on <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
              If you want to reuse their source code, please credit them appropriately.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
